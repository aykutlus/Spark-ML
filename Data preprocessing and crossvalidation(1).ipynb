{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requiered libriaries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set spark session\n",
    "spark_session = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = spark_session\\\n",
    "        .read\\\n",
    "        .format(\"csv\")\\\n",
    "        .options(header='false', inferschema='true', delimiter=',')\\\n",
    "        .load(\"/home/master/wine.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, _c1: double, _c2: double, _c3: double, _c4: double, _c5: int, _c6: double, _c7: double, _c8: double, _c9: double, _c10: double, _c11: double, _c12: double, _c13: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: double (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: double (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: double (nullable = true)\n",
      " |-- _c7: double (nullable = true)\n",
      " |-- _c8: double (nullable = true)\n",
      " |-- _c9: double (nullable = true)\n",
      " |-- _c10: double (nullable = true)\n",
      " |-- _c11: double (nullable = true)\n",
      " |-- _c12: double (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n",
      "|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7| _c8| _c9|_c10|_c11|_c12|_c13|\n",
      "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n",
      "|  1|14.23|1.71|2.43|15.6|127| 2.8|3.06|0.28|2.29|5.64|1.04|3.92|1065|\n",
      "|  1| 13.2|1.78|2.14|11.2|100|2.65|2.76|0.26|1.28|4.38|1.05| 3.4|1050|\n",
      "|  1|13.16|2.36|2.67|18.6|101| 2.8|3.24| 0.3|2.81|5.68|1.03|3.17|1185|\n",
      "|  1|14.37|1.95| 2.5|16.8|113|3.85|3.49|0.24|2.18| 7.8|0.86|3.45|1480|\n",
      "|  1|13.24|2.59|2.87|21.0|118| 2.8|2.69|0.39|1.82|4.32|1.04|2.93| 735|\n",
      "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Think to optimize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = dataset.select(\"_c0\").rdd.flatMap(lambda x: x).collect()\n",
    "c1 = dataset.select(\"_c1\").rdd.flatMap(lambda x: x).collect()\n",
    "c2 = dataset.select(\"_c2\").rdd.flatMap(lambda x: x).collect()\n",
    "c3 = dataset.select(\"_c3\").rdd.flatMap(lambda x: x).collect()\n",
    "c4 = dataset.select(\"_c4\").rdd.flatMap(lambda x: x).collect()\n",
    "c5 = dataset.select(\"_c5\").rdd.flatMap(lambda x: x).collect()\n",
    "c6 = dataset.select(\"_c6\").rdd.flatMap(lambda x: x).collect()\n",
    "c7 = dataset.select(\"_c7\").rdd.flatMap(lambda x: x).collect()\n",
    "c8 = dataset.select(\"_c8\").rdd.flatMap(lambda x: x).collect()\n",
    "c9 = dataset.select(\"_c9\").rdd.flatMap(lambda x: x).collect()\n",
    "c10 = dataset.select(\"_c10\").rdd.flatMap(lambda x: x).collect()\n",
    "c11 = dataset.select(\"_c11\").rdd.flatMap(lambda x: x).collect()\n",
    "c12 = dataset.select(\"_c12\").rdd.flatMap(lambda x: x).collect()\n",
    "c13 = dataset.select(\"_c13\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([13.2, 1.78, 2.14, 11.2, 100.0, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.4, 1050.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector=[]\n",
    "\n",
    "for i in np.arange(0,len(c0)):\n",
    "    vector.append(Vectors.dense([c1[i],c2[i],c3[i],c4[i],c5[i],c6[i],c7[i],c8[i],c9[i],c10[i],c11[i],c12[i],c13[i]]))\n",
    "vector[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zip(c0,vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_session.createDataFrame(data, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: long (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[14.23,1.71,2.43,...|\n",
      "|    1|[13.2,1.78,2.14,1...|\n",
      "|    1|[13.16,2.36,2.67,...|\n",
      "|    1|[14.37,1.95,2.5,1...|\n",
      "|    1|[13.24,2.59,2.87,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(df)\n",
    "\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 3 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=3).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "train, test = df.randomSplit([0.70, 0.30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a decision tree MODEL\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxDepth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute accuracy\n",
    "dtevaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "dtparamGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [2, 5, 10, 20, 30])\n",
    "             .addGrid(dt.maxBins, [10, 20, 40, 80, 100])\n",
    "             .build())\n",
    "\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "# Estimator will be pipeline which we created.\n",
    "dtcv = CrossValidator(estimator = pipeline,\n",
    "                      estimatorParamMaps = dtparamGrid,\n",
    "                      evaluator = dtevaluator,\n",
    "                      numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidatorModel_68455aa78009\n"
     ]
    }
   ],
   "source": [
    "# Run cross validations\n",
    "dtcvModel = dtcv.fit(train)\n",
    "print(dtcvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='DecisionTreeClassifier_567dc2be85dd', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='DecisionTreeClassifier_567dc2be85dd', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10}\n"
     ]
    }
   ],
   "source": [
    "#Get the best params\n",
    "print(dtcvModel.getEstimatorParamMaps()[np.argmax(dtcvModel.avgMetrics)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, best params for this cross validation are:\n",
    "    maxDepth:5\n",
    "    maxBins:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='DecisionTreeClassifier_567dc2be85dd', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False,\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10,\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='featuresCol', doc='features column name'): 'indexedFeatures',\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='labelCol', doc='label column name'): 'indexedLabel',\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256,\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1,\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability',\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent='DecisionTreeClassifier_567dc2be85dd', name='seed', doc='random seed'): -3083581696531915666}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all params of best model\n",
    "best_mod = dtcvModel.bestModel\n",
    "param_dict = best_mod.stages[2].extractParamMap()\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above output, we can see all variable that has best our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "dtpredictions = dtcvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+--------------------+--------------+-------------+----------+\n",
      "|label|            features|indexedLabel|     indexedFeatures| rawPrediction|  probability|prediction|\n",
      "+-----+--------------------+------------+--------------------+--------------+-------------+----------+\n",
      "|    1|[13.05,1.65,2.55,...|         1.0|[13.05,1.65,2.55,...|[0.0,40.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.07,1.5,2.1,15...|         1.0|[13.07,1.5,2.1,15...|[0.0,40.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.2,1.78,2.14,1...|         1.0|[13.2,1.78,2.14,1...|[0.0,40.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.24,3.98,2.29,...|         1.0|[13.24,3.98,2.29,...|[39.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|    1|[13.51,1.8,2.65,1...|         1.0|[13.51,1.8,2.65,1...|[0.0,40.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "+-----+--------------------+------------+--------------------+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtpredictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9038461538461539\n",
      "---------------------------------------------\n",
      "Confusion Matrix:\n",
      " DenseMatrix([[19.,  1.,  0.],\n",
      "             [ 2., 17.,  0.],\n",
      "             [ 2.,  0., 11.]])\n",
      "---------------------------------------------\n",
      "F1 Score: 0.918918918918919\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model\n",
    "print('Accuracy:', dtevaluator.evaluate(dtpredictions))\n",
    "print(\"---------------------------------------------\")\n",
    "lrmetrics = MulticlassMetrics(dtpredictions['indexedLabel','prediction'].rdd)\n",
    "print('Confusion Matrix:\\n', lrmetrics.confusionMatrix())\n",
    "print(\"---------------------------------------------\")\n",
    "print('F1 Score:', lrmetrics.fMeasure(1.0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
